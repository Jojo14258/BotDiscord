"""
Service IA pour la g√©n√©ration et v√©rification des questions
"""
import random
from openai import OpenAI
from config.settings import settings
from utils.exceptions import SpecialiteInvalide

class AIService:
    """Service pour les interactions avec l'IA"""
    
    def __init__(self):
        self.client = OpenAI(
            base_url=settings.AI_BASE_URL,
            api_key=settings.AI_TOKEN
        )
        self.model_name = settings.AI_MODEL
    
    async def generate_question(self, difficulty: int, speciality: str) -> str:
        """G√©n√®re une question selon la difficult√© et sp√©cialit√©"""
        
        # Choisir la sp√©cialit√©
        if speciality == "random":
            speciality_chosen = random.choice(settings.SPECIALITES)
        elif speciality in settings.SPECIALITES:
            speciality_chosen = speciality
        else:
            raise SpecialiteInvalide()
        
        # D√©finir le niveau selon la difficult√©
        if difficulty == 1:
            level = "facile et direct"
        elif difficulty == 2:
            level = "moyen, un peu plus pi√©geux"
        else:
            level = "complexe et demandant plus de r√©flexion"
        
        # Cr√©er le prompt
        prompt = f"""
Tu es un assistant qui g√©n√®re des questions de quiz pour aider les lyc√©ens √† r√©viser leur sp√©.

G√©n√®re une question de quiz **{level}**, mais r√©soluble en moins de 30 secondes, pour un √©l√®ve de terminale sp√©, dans la sp√©cialit√© suivante : {speciality_chosen}.
Attention, la question doit bien faire partie du programme de lyc√©e. 
Donne uniquement la question suivie de sa r√©ponse attendue, dans ce format :

Sujet: {speciality_chosen}
Question: [Texte de la question]
R√©ponse: [La bonne r√©ponse]
"""
        
        # Appel API
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "Tu es un assistant qui g√©n√®re des questions de quiz pour des lyc√©ens."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.9,
            max_tokens=500
        )
        
        return response.choices[0].message.content.strip()
    
    async def verify_answer(self, question: str, expected_answer: str, user_answer: str) -> tuple[str, bool]:
        """V√©rifie si la r√©ponse de l'utilisateur est correcte"""
        
        prompt = f"""
Tu es un assistant bienveillant et sympathique charg√© d'√©valuer si la r√©ponse d'un utilisateur √† un quiz est correcte.

Voici la question pos√©e :
{question}

Voici la bonne r√©ponse attendue :
{expected_answer}

Voici ce que l'utilisateur a r√©pondu :
{user_answer}

Ta mission :
1. Indique si la r√©ponse est correcte ou non.
2. Commence toujours par "‚úÖ Bien jou√© !" si c'est correct, ou "‚ùå Oups..." si c'est incorrect.
3. Si la r√©ponse est fausse, donne la bonne r√©ponse, avec une explication claire, simple et sans jugement.
4. Termine par [OK=true] si la r√©ponse est correcte, sinon [OK=false].
5. Utilise un ton amical, motivant et encourageant ‚Äì comme un prof sympa qui veut aider.

Exemples :
‚úÖ Bien jou√© ! Ta r√©ponse est correcte. (...)
[OK=true]

‚ùå Oups... Ce n'est pas tout √† fait √ßa. La bonne r√©ponse est : (...). Mais ne t'inqui√®te pas, tu vas progresser ! üí™
[OK=false]
"""
        
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        
        text = response.choices[0].message.content.strip()
        
        # D√©termine si la r√©ponse est correcte
        is_correct = "[OK=true]" in text
        
        # Nettoie le commentaire
        comment = text.replace("[OK=true]", "").replace("[OK=false]", "").strip()
        
        return comment, is_correct

# Instance globale
ai_service = AIService()
